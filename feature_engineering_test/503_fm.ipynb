{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from pyfm import pylibfm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import xgboost as xgb\n",
    "from utils import raw_data_path,dump_pickle,load_pickle,cal_log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "import lightgbm as lgb\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shap: (278805, 370)\n",
      "cv shape (63610, 370)\n",
      "test shape (57411, 370)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 342415/342415 [00:02<00:00, 156393.16it/s]\n",
      "100%|██████████| 57411/57411 [00:00<00:00, 150320.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "train\n",
      "test\n",
      "Creating validation dataset of 0.01 of training for adaptive regularization\n",
      "-- Epoch 1\n",
      "Training log loss: nan\n",
      "-- Epoch 2\n",
      "Training log loss: nan\n",
      "-- Epoch 3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-33937eb3f8aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mfm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpylibfm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_factors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"classification\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_learning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate_schedule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"optimal\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mfm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/pyfm/pylibfm.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    208\u001b[0m                                verbose)\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfm_fast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;31m# report epoch information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpyfm_fast.pyx\u001b[0m in \u001b[0;36mpyfm_fast.FM_fast.fit (pyfm_fast.c:6068)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "train_data = load_pickle(path='../data_valid/train_final_onehot.pkl')    \n",
    "train_Y = train_data['is_trade']\n",
    "train_data.drop('is_trade', axis=1, inplace=True) \n",
    "\n",
    "\n",
    "cv_data = load_pickle(path='../data_valid/valid_final_onehot.pkl')\n",
    "cv_Y = cv_data['is_trade']\n",
    "cv_data.drop('is_trade', axis=1, inplace=True) \n",
    "\n",
    "\n",
    "test_data = load_pickle(path='../data_valid/test_final_onehot.pkl')\n",
    "test_Y = test_data['is_trade']\n",
    "test_data.drop('is_trade', axis=1, inplace=True) \n",
    "\n",
    "print('train shap:',train_data.shape)\n",
    "print('cv shape', cv_data.shape)\n",
    "print('test shape', test_data.shape)\n",
    "\n",
    "\n",
    "test_file = 'round1_ijcai_18_test_a_20180301.txt'\n",
    "test = pd.read_table(raw_data_path + test_file,delim_whitespace=True)\n",
    "test_id = test.instance_id\n",
    "\n",
    "drop_cols = ['context_id', 'user_id', 'shop_id', 'item_id','item_brand_id', 'instance_id']\n",
    "\n",
    "train_data.drop(drop_cols,axis=1,inplace=True)\n",
    "cv_data.drop(drop_cols,axis=1,inplace=True)\n",
    "test_data.drop(drop_cols,axis=1,inplace=True)\n",
    "\n",
    "train_data = pd.concat([train_data, cv_data], axis=0).reset_index(drop=True)\n",
    "train_Y =  pd.concat([train_Y, cv_Y], axis=0).reset_index(drop=True)\n",
    "\n",
    "df = pd.concat([train_data, test_data], axis=0).reset_index(drop=True)\n",
    "X = minmax_scale(df.values)\n",
    "train_data = df.iloc[:len(train_data), :]\n",
    "test_data= df.iloc[len(train_data):, :]\n",
    "\n",
    "train_data = [ {v: k for k, v in dict(zip(i, range(len(i)))).items()}  for i in tqdm(train_data.values[:, :10])]\n",
    "test_data = [ {v: k for k, v in dict(zip(i, range(len(i)))).items()}  for i in tqdm(test_data.values[:, :10])]\n",
    "\n",
    "print('start')\n",
    "v = DictVectorizer()\n",
    "train_data = v.fit_transform(train_data)\n",
    "print('train')\n",
    "test_data = v.transform(test_data)\n",
    "print('test')\n",
    "\n",
    "fm = pylibfm.FM(num_factors=50, num_iter=10, verbose=True, task=\"classification\", initial_learning_rate=0.0001, learning_rate_schedule=\"optimal\")\n",
    "\n",
    "fm.fit(train_data,train_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from pyfm import pylibfm\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=1000,n_features=100, n_clusters_per_class=1)\n",
    "data = [ {v: k for k, v in dict(zip(i, range(len(i)))).items()}  for i in X]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.1, random_state=42)\n",
    "\n",
    "v = DictVectorizer()\n",
    "X_train = v.fit_transform(X_train)\n",
    "X_test = v.transform(X_test)\n",
    "\n",
    "fm = pylibfm.FM(num_factors=50, num_iter=10, verbose=True, task=\"classification\", initial_learning_rate=0.0001, learning_rate_schedule=\"optimal\")\n",
    "\n",
    "fm.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<900x100 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 90000 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.52770943,  0.41027511, -1.00857925, ..., -0.61487631,\n",
       "         0.68592807,  0.96337477],\n",
       "       [-1.01593181, -1.33901732,  0.56640636, ..., -0.74931004,\n",
       "        -0.26838766,  0.75300492],\n",
       "       [-0.23765329, -0.1173272 , -0.53645908, ..., -1.95776431,\n",
       "         0.83088056,  1.25895347],\n",
       "       ...,\n",
       "       [-0.70869261,  0.43685178, -0.78968643, ..., -0.17278409,\n",
       "        -0.64347372,  1.19003026],\n",
       "       [-0.01723435,  2.07002903,  0.74066149, ..., -1.30170852,\n",
       "         0.06403428, -0.46236565],\n",
       "       [-2.44099018,  0.69927239,  2.63653614, ..., -2.509899  ,\n",
       "        -1.01678362,  1.18424685]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
