{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item \n",
    "from utils import BayesianSmoothing, load_pickle, dump_pickle, raw_data_path, valid_data_path\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "\n",
    "train = load_pickle('../data_valid/train.pkl')\n",
    "test = load_pickle('../data_valid/test.pkl')\n",
    "df = pd.concat([train, test], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(420676, 36) (57411, 36)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape,test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "100%|██████████| 7/7 [00:05<00:00,  1.28it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "100%|██████████| 2/2 [00:00<00:00,  7.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed 8.447350025177002\n"
     ]
    }
   ],
   "source": [
    "def item_time_count(df):\n",
    "    # ========================= 产品当天被搜索次数和当前小时被搜索次数 =========================================\n",
    "    time_features = ['hour', 'day']\n",
    "    item_features = ['item_id', 'item_brand_id', 'item_city_id', 'item_price_level', 'item_sales_level','item_collected_level','item_pv_level']\n",
    "\n",
    "    item_time_df = pd.DataFrame()\n",
    "    item_time_df = df[['instance_id', 'day']]\n",
    "\n",
    "    for item_feature in tqdm(item_features):\n",
    "        for time_feature in time_features:\n",
    "            search_group = df.groupby([item_feature, time_feature]).count().reset_index()\n",
    "            tmp_df = df[[item_feature, time_feature]]\n",
    "            item_day_search = pd.merge(tmp_df, search_group, on=[item_feature, time_feature], how='left').iloc[:, -1]\n",
    "            item_time_df['{}_{}_search'.format(item_feature, time_feature)] = item_day_search\n",
    "    \n",
    "    train_feat = item_time_df[(item_time_df['day'] >= 18) & (item_time_df['day'] <= 23)].drop('day', axis=1)\n",
    "    test_feat = item_time_df[item_time_df['day']==24].drop('day', axis=1)\n",
    "    dump_pickle(train_feat, path=valid_data_path+'train_feature/'+'303_user_time_count.pkl')\n",
    "    dump_pickle(test_feat, path=valid_data_path+'test_feature/'+'303_user_time_count.pkl')\n",
    "    \n",
    "    # ======================== 产品当前被搜索距离上次的时间 ================================================\n",
    "    df_tmp = df[['instance_id', 'item_id',  'context_timestamp', 'day']].copy()\n",
    "    df_tmp.sort_values(['item_id', 'context_timestamp'], inplace=True)\n",
    "\n",
    "    df_tmp['item_t-1_context_timestamp'] = df_tmp.groupby('item_id')['context_timestamp'].shift(1)\n",
    "    df_tmp['item_time_diff_last_query'] = df_tmp['context_timestamp'] - df_tmp['item_t-1_context_timestamp']\n",
    "    # df_tmp['item_time_diff_last_query'] = np.log1p(df_tmp['context_timestamp'] - df_tmp['item_t-1_context_timestamp'])\n",
    "\n",
    "    train_feat = df_tmp[(df_tmp['day'] >= 18) & (df_tmp['day'] <= 23)].drop('day', axis=1)   \n",
    "    train_feat = train_feat[['instance_id', 'item_time_diff_last_query']]\n",
    "    \n",
    "    test_feat = df_tmp[df_tmp['day']==24].drop('day', axis=1)   \n",
    "    test_feat = test_feat[['instance_id', 'item_time_diff_last_query']]\n",
    "    \n",
    "    dump_pickle(train_feat, path=valid_data_path+'train_feature/'+'303_feature_last_query.pkl')\n",
    "    dump_pickle(test_feat, path=valid_data_path+'test_feature/'+'303_feature_last_query.pkl')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ========================= 当日当前搜索距离上次的时间(商品，商标) ==========================================\n",
    "    final_feat = pd.DataFrame()\n",
    "    final_feat = df[['instance_id', 'day']]\n",
    "    cols = ['item_id', 'item_brand_id']\n",
    "    for col in tqdm(cols):\n",
    "        df_select = df[[col,'day','context_timestamp']]\n",
    "        df_group =  df_select.groupby([col,'day'])\n",
    "        group_max = df_group['context_timestamp'].transform('max')\n",
    "        group_min = df_group['context_timestamp'].transform('min')\n",
    "        final_feat['item_id_diff_maxtime_{}'.format(col)] = group_max - df['context_timestamp'].values\n",
    "        final_feat['item_id_diff_mintime_{}'.format(col)] = df['context_timestamp'].values -group_min\n",
    "        \n",
    "    train_feat = final_feat[(final_feat['day'] >= 18) & (final_feat['day'] <= 23)].drop('day', axis=1)       \n",
    "    test_feat = final_feat[final_feat['day']==24].drop('day', axis=1)   \n",
    "\n",
    "    dump_pickle(train_feat, path=valid_data_path+'train_feature/'+'303_item_diff_max_min.pkl')\n",
    "    dump_pickle(test_feat, path=valid_data_path+'test_feature/'+'303_item_diff_max_min.pkl')    \n",
    "        \n",
    "    \n",
    "    \n",
    "    # ================================= 当前日期前一天的cnt ===========================================\n",
    "    count_features = ['item_brand_id', 'item_city_id', 'item_price_level', 'item_sales_level','item_collected_level','item_pv_level']\n",
    "    final_feat = df[count_features+['instance_id', 'day']]\n",
    "    for col in count_features:\n",
    "        count_name = '{}_lastday_count'.format(col)\n",
    "        count_all = None\n",
    "        for d in range(18, 24):\n",
    "            col_cnt = df[df['day'] == d - 1].groupby(by=col)['instance_id'].count().reset_index()\n",
    "            col_cnt.columns = [col, count_name]\n",
    "            col_cnt['day'] = d\n",
    "            count_all = pd.concat([count_all, col_cnt], axis=0)\n",
    "        final_feat = pd.merge(final_feat, count_all, on=[col, 'day'], how='left')\n",
    "#     final_feat = final_feat.drop(count_features+['day'], axis=1)\n",
    "\n",
    "    train_feat = final_feat[(final_feat['day'] >= 18) & (final_feat['day'] <= 23)]  \n",
    "    test_feat = final_feat[final_feat['day']==24]\n",
    "    train_feat = train_feat.drop(count_features+['day'], axis=1)\n",
    "    test_feat = test_feat.drop(count_features+['day'], axis=1)\n",
    "    \n",
    "    dump_pickle(train_feat, path=valid_data_path+'train_feature/'+'303_item_last_day_count.pkl')\n",
    "    dump_pickle(test_feat, path=valid_data_path+'test_feature/'+'303_item_last_day_count.pkl')\n",
    "\n",
    "start = time.time()\n",
    "item_time_count(df)\n",
    "end = time.time()\n",
    "print('time elapsed {}'.format(end-start))\n",
    "#     print(final_feat.columns)\n",
    "#     print('the shape of {} {}'.format(mode, final_feat.shape))\n",
    "\n",
    "#     dump_pickle(final_feat, path=raw_data_path + '{}_feature/'.format(mode) + '302_item_last_day_count.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
