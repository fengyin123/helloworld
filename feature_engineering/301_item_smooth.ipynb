{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import BayesianSmoothing, load_pickle, dump_pickle, raw_data_path\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "train = load_pickle('../data/train.pkl')\n",
    "test = load_pickle('../data/test.pkl')\n",
    "df = pd.concat([train, test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|█▍        | 1/7 [00:00<00:04,  1.21it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:01<00:04,  1.11it/s]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:02<00:03,  1.04it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:04<00:03,  1.03s/it]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:05<00:02,  1.10s/it]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:06<00:01,  1.15s/it]\u001b[A\n",
      "100%|██████████| 7/7 [00:08<00:00,  1.20s/it]\u001b[A\n",
      " 14%|█▍        | 1/7 [00:08<00:51,  8.54s/it]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|█▍        | 1/7 [00:00<00:02,  2.62it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:00<00:01,  2.80it/s]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:01<00:01,  2.79it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:01<00:01,  2.64it/s]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:01<00:00,  2.51it/s]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:02<00:00,  2.39it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:03<00:00,  2.30it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:11<00:29,  5.85s/it]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|█▍        | 1/7 [00:00<00:01,  3.55it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:00<00:01,  4.74it/s]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:00<00:00,  5.33it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:00<00:00,  5.47it/s]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:00<00:00,  5.27it/s]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:01<00:00,  4.98it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:01<00:00,  4.61it/s]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:13<00:17,  4.44s/it]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|█▍        | 1/7 [00:00<00:01,  4.37it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:00<00:00,  5.81it/s]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:00<00:00,  6.11it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:00<00:00,  5.81it/s]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:00<00:00,  5.62it/s]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:01<00:00,  5.08it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:01<00:00,  4.58it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:14<00:11,  3.75s/it]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|█▍        | 1/7 [00:00<00:01,  4.12it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:00<00:00,  5.66it/s]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:00<00:00,  6.22it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:00<00:00,  6.23it/s]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:00<00:00,  5.92it/s]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:01<00:00,  5.49it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:01<00:00,  5.14it/s]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:16<00:06,  3.31s/it]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|█▍        | 1/7 [00:00<00:01,  4.03it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:00<00:00,  5.57it/s]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:00<00:00,  6.05it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:00<00:00,  6.04it/s]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:00<00:00,  5.67it/s]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:01<00:00,  5.31it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:01<00:00,  4.87it/s]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:18<00:03,  3.02s/it]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|█▍        | 1/7 [00:00<00:01,  3.43it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:00<00:01,  4.62it/s]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:00<00:00,  5.03it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:00<00:00,  5.03it/s]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:01<00:00,  4.65it/s]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:01<00:00,  4.49it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:01<00:00,  4.33it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:19<00:00,  2.85s/it]\n"
     ]
    }
   ],
   "source": [
    "iter_num = 100\n",
    "epsilon = 0.001\n",
    "'''\n",
    "1. 定义需要计算平滑点击率的变量\n",
    "2. 对于每一天，找出在这之前的所有点击行为\n",
    "3. 统计该变量的点击次数和购买次数\n",
    "'''\n",
    "smooth_cols = ['item_id', 'item_brand_id', 'item_city_id', 'item_price_level', 'item_sales_level','item_collected_level','item_pv_level']\n",
    "\n",
    "smooth_train = train[smooth_cols + ['instance_id', 'day']]\n",
    "smooth_test = test[smooth_cols + ['instance_id','day']]\n",
    "for col in tqdm(smooth_cols):\n",
    "    col_I = '{}_I'.format(col)\n",
    "    col_C = '{}_C'.format(col)\n",
    "    col_smooth_rate = '{}_smooth_rate'.format(col)\n",
    "    train[col_smooth_rate] = -1\n",
    "    smooth_all = pd.DataFrame({'day': train.day, '{}'.format(col): train[col]})\n",
    "    CVR_all = None\n",
    "    for day in tqdm(range(19, 26)):\n",
    "        I = train[train.day<day].groupby(col)['is_trade'].count().reset_index()\n",
    "        I.columns = [col, col_I]\n",
    "        C = train[train.day<day].groupby(col)['is_trade'].sum().reset_index()\n",
    "        C.columns = [col, col_C]\n",
    "        CVR = pd.concat([I, C[col_C]], axis=1)\n",
    "        CVR['day'] = day\n",
    "\n",
    "        smooth = BayesianSmoothing(1, 1)\n",
    "        smooth.update(CVR[col_I].values, CVR[col_C].values, iter_num, epsilon)\n",
    "        alpha = smooth.alpha\n",
    "        beta = smooth.beta\n",
    "        CVR[col_smooth_rate] = (CVR[col_C] + alpha) / (CVR[col_I] + alpha + beta)\n",
    "        CVR_all = pd.concat([CVR_all, CVR], axis=0)\n",
    "        \n",
    "    smooth_train = pd.merge(smooth_train, CVR_all[[col, 'day', col_smooth_rate]], on=[col, 'day'], how='left')\n",
    "    smooth_test = pd.merge(smooth_test, CVR_all[[col, 'day', col_smooth_rate]], on=[col, 'day'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['instance_id', 'item_id_smooth_rate', 'item_brand_id_smooth_rate',\n",
      "       'item_city_id_smooth_rate', 'item_price_level_smooth_rate',\n",
      "       'item_sales_level_smooth_rate', 'item_collected_level_smooth_rate',\n",
      "       'item_pv_level_smooth_rate'],\n",
      "      dtype='object')\n",
      "the shape of train (478087, 8)\n",
      "the shape of test (18371, 8)\n"
     ]
    }
   ],
   "source": [
    "smooth_train.drop(['day'], axis=1, inplace=True)\n",
    "smooth_test.drop(['day'], axis=1, inplace=True)\n",
    "smooth_train.drop(smooth_cols,axis=1,inplace=True)\n",
    "smooth_test.drop(smooth_cols,axis=1,inplace=True)\n",
    "print(smooth_train.columns)\n",
    "print('the shape of train {}'.format(smooth_train.shape))\n",
    "print('the shape of test {}'.format(smooth_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_pickle(smooth_train, path='../data/train_feature/301_smooth_item_features.pkl')\n",
    "dump_pickle(smooth_test, path='../data/test_feature/301_smooth_item_features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
