{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data\n",
      "the shape of train (478087, 27)\n",
      "the shape of test (42888, 26)\n",
      "Start doing preprocessing\n",
      "========================item==========================\n",
      "========================user==========================\n",
      "=====================context==========================\n",
      "=====================shop===============================\n",
      "the shape of train (420676, 36)\n",
      "Int64Index([     0,      1,      2,      3,      4,      5,      6,      7,\n",
      "                 8,      9,\n",
      "            ...\n",
      "            420666, 420667, 420668, 420669, 420670, 420671, 420672, 420673,\n",
      "            420674, 420675],\n",
      "           dtype='int64', length=420676)\n",
      "the shape of test (57411, 36)\n",
      "Preprocessing done and time elapsed 26.7400541305542\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn import preprocessing\n",
    "import warnings\n",
    "import datetime\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time\n",
    "\n",
    "from utils import raw_data_path, dump_pickle\n",
    "\n",
    "path = '../data/'\n",
    "train_file = 'round1_ijcai_18_train_20180301.txt'\n",
    "test_file = 'round1_ijcai_18_test_b_20180418.txt'\n",
    "\n",
    "\n",
    "\n",
    "# def load_data():\n",
    "#     train = pd.read_table(path + train_file, encoding='utf8', delim_whitespace=True)\n",
    "#     test = pd.read_table(path + train_file, encoding='utf8', delim_whitespace=True)\n",
    "#     df = pd.concat([train, test], axis=0, ignore_index=True)\n",
    "\n",
    "def date_convert(data):\n",
    "    # Transform into datetime format\n",
    "    data['time'] = pd.to_datetime(data.context_timestamp, unit='s')\n",
    "\n",
    "    # transform into Beijing datetime format\n",
    "    data['realtime'] = data['time'].apply(lambda x: x + datetime.timedelta(hours=8))\n",
    "    data['day'] = data['realtime'].dt.day\n",
    "    data['hour'] = data['realtime'].dt.hour\n",
    "    \n",
    "    return data\n",
    "\n",
    "def base_process(data):\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    print(\"========================item==========================\")\n",
    "    # Divided into different category levels and LabelEncoder()\n",
    "    '''\n",
    "    item_id, item_category_list, item_property_list, item_brand_id, item_city_id, \n",
    "    item_price_level, item_sales_level, item_collected_level, item_pv_level\n",
    "    '''\n",
    "    for i in range(1, 3):\n",
    "        data['item_category_list' + str(i)] = lbl.fit_transform(data['item_category_list'].map(\n",
    "            lambda x: str(str(x).split(';')[i]) if len(str(x).split(';')) > i else 'missing'))\n",
    "    del data['item_category_list'] \n",
    "        \n",
    "#     for i in range(10):\n",
    "#         data['item_property_list' + str(i)] = lbl.fit_transform(data['item_property_list'].map(\n",
    "#             lambda x: str(str(x).split(';')[i]) if len(str(x).split(';')) > i else ''))\n",
    "#     del data['item_property_list']\n",
    "    # train_item_properitem_property_listty = data['item_property_list'].str.split(';', expand=True).add_prefix('item_property_')\n",
    "    # train_item_property.fillna('missing', inplace=True)\n",
    "    # train_item_property = lbl.fit_transform(train_item_property)\n",
    "    # data = pd.concat([data, train_item_property], axis=1)\n",
    "\n",
    "    for col in ['item_id', 'item_brand_id', 'item_city_id']:\n",
    "        data[col] = lbl.fit_transform(data[col])\n",
    "    \n",
    "    # Fill none with mean\n",
    "    data['item_sales_level'][data.item_sales_level==-1] = None\n",
    "    data['item_sales_level'].fillna(data['item_sales_level'].mean(), inplace=True)\n",
    "    \n",
    "    \n",
    "    print(\"========================user==========================\")\n",
    "    # user_gender_id and user_occupation_id should be handled with one-hot\n",
    "    data[data.user_age_level==-1]['user_age_level'] = None\n",
    "    data['user_age_level'].fillna(data['user_age_level'].mode())\n",
    "    data['user_age_level'] = data['user_age_level'].apply(lambda x: x%1000)\n",
    "    \n",
    "    data[data.user_star_level==-1]['user_star_level'] = None\n",
    "    data['user_star_level'].fillna(data['user_star_level'].mean())\n",
    "    data['user_star_level'] = data['user_star_level'].apply(lambda x: x%3000)\n",
    "    \n",
    "    \n",
    "    print(\"=====================context==========================\")\n",
    "    data = date_convert(data)\n",
    "    \n",
    "    for i in range(5):\n",
    "        data['predict_category_property' + str(i)] = lbl.fit_transform(data['predict_category_property'].map(\n",
    "            lambda x: str(str(x).split(';')[i]) if len(str(x).split(';')) > i else ''))\n",
    "    del data['predict_category_property'] \n",
    "        \n",
    "    print(\"=====================shop===============================\")\n",
    "    data['shop_score_service'][data.shop_score_service==-1] = None\n",
    "    data['shop_score_service'].fillna(data['shop_score_service'].mean(), inplace=True)\n",
    "    \n",
    "    data['user_age_level'][data.user_age_level==-1] = None\n",
    "    data['shop_score_delivery'].fillna(data['shop_score_delivery'].mean(), inplace=True)\n",
    "    \n",
    "    data['shop_score_description'][data.shop_score_description==-1] = None\n",
    "    data['shop_score_description'].fillna(data['shop_score_description'].mean(), inplace=True)\n",
    "    \n",
    "    return data\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start = time.time()\n",
    "    print(\"Load Data\")\n",
    "    train = pd.read_table(path + train_file, encoding='utf8', delim_whitespace=True)\n",
    "    test = pd.read_table(path + test_file, encoding='utf8', delim_whitespace=True)\n",
    "    train.drop_duplicates('instance_id', inplace=True)\n",
    "    test.drop_duplicates('instance_id', inplace=True)\n",
    "    print('the shape of train {}'.format(train.shape))\n",
    "    print('the shape of test {}'.format(test.shape))\n",
    "    len_train = train.shape[0]\n",
    "#     df = pd.concat([train, test], axis=0, ignore_index=True)\n",
    "    df = train\n",
    "    print(\"Start doing preprocessing\")\n",
    "    \n",
    "    df = base_process(df)\n",
    "    dump_pickle(df, path=raw_data_path + 'df.pkl')\n",
    "    \n",
    "    train = df[(df['day'] >= 18) & (df['day'] <= 23)]\n",
    "    train.index = np.arange(0, len(train))\n",
    "    print('the shape of train {}'.format(train.shape))\n",
    "    print(train.index)\n",
    "    dump_pickle(train, path='../data_valid/train.pkl')\n",
    "    \n",
    "    test = df[df['day'] == 24]\n",
    "    test.index = np.arange(len(train), len(train)+len(test))\n",
    "    print('the shape of test {}'.format(test.shape))\n",
    "    dump_pickle(test, path='../data_valid/test.pkl')\n",
    "    \n",
    "    end = time.time()\n",
    "    print(\"Preprocessing done and time elapsed %s\" % (end-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "day\n",
       "18    0.019933\n",
       "19    0.019626\n",
       "20    0.019319\n",
       "21    0.019258\n",
       "22    0.018826\n",
       "23    0.017230\n",
       "24    0.016861\n",
       "Name: is_trade, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('day').is_trade.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
