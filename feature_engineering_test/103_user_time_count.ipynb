{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "100%|██████████| 5/5 [00:05<00:00,  1.05s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel_launcher.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel_launcher.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed 8.361943006515503\n"
     ]
    }
   ],
   "source": [
    "# %load 103_user_time_count.py\n",
    "# 计算出至今为止用户买的产品数\n",
    "from utils import BayesianSmoothing, load_pickle, dump_pickle, raw_data_path\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "\n",
    "train = load_pickle('../data/train.pkl')\n",
    "test = load_pickle('../data/test.pkl')\n",
    "df = pd.concat([train, test], axis=0)\n",
    "\n",
    "def user_time_count(df):\n",
    "    # ========================= 当天搜索次数和当前小时搜索次数 =========================================\n",
    "    time_features = ['hour', 'day']\n",
    "    user_features = ['user_id', 'user_gender_id', 'user_age_level', 'user_occupation_id', 'user_star_level']\n",
    "\n",
    "    user_time_df = pd.DataFrame()\n",
    "    user_time_df = df[['instance_id', 'day']]\n",
    "\n",
    "    for user_feature in tqdm(user_features):\n",
    "        for time_feature in time_features:\n",
    "            search_group = df.groupby([user_feature, time_feature]).count().reset_index()\n",
    "            tmp_df = df[[user_feature, time_feature]]\n",
    "            user_day_search = pd.merge(tmp_df, search_group, on=[user_feature, time_feature], how='left').iloc[:, -1]\n",
    "            user_time_df['{}_{}_search'.format(user_feature, time_feature)] = user_day_search\n",
    "            \n",
    "    train_feat = user_time_df[(user_time_df['day'] >= 18) & (user_time_df['day'] <= 24)].drop('day', axis=1)\n",
    "    test_feat = user_time_df[user_time_df['day']==25].drop('day', axis=1)\n",
    "    dump_pickle(train_feat, path='../data/train_feature/103_user_time_count.pkl')\n",
    "    dump_pickle(test_feat, path='../data/test_feature/103_user_time_count.pkl')\n",
    "\n",
    "\n",
    "    # ======================== 用户当前搜索距离上次的时间 ================================================\n",
    "    df_tmp = df[['instance_id', 'user_id',  'context_timestamp', 'day']].copy()\n",
    "    df_tmp.sort_values(['user_id', 'context_timestamp'], inplace=True)\n",
    "\n",
    "\n",
    "    df_tmp['t-1_context_timestamp'] = df_tmp.groupby('user_id')['context_timestamp'].shift(1)\n",
    "    df_tmp['time_diff_last_query'] = np.log1p(df_tmp['context_timestamp'] - df_tmp['t-1_context_timestamp'])\n",
    "\n",
    "    train_feat = df_tmp[(df_tmp['day'] >= 18) & (df_tmp['day'] <= 24)].drop('day', axis=1)   \n",
    "    train_feat = train_feat[['instance_id', 'time_diff_last_query']]\n",
    "    \n",
    "    test_feat = df_tmp[df_tmp['day']==25].drop('day', axis=1)   \n",
    "    test_feat = test_feat[['instance_id', 'time_diff_last_query']]\n",
    "    \n",
    "    dump_pickle(train_feat, path='../data/train_feature/103_feature_last_query.pkl')\n",
    "    dump_pickle(test_feat, path='../data/test_feature/103_feature_last_query.pkl')\n",
    "\n",
    "\n",
    "    # ========================= 当日用户当前搜索距离上次的时间(商品，商店，商标) ==========================================\n",
    "    final_feat = pd.DataFrame()\n",
    "    final_feat = df[['instance_id', 'day']]\n",
    "    cols = ['item_id', 'shop_id', 'item_brand_id']\n",
    "    for col in tqdm(cols):\n",
    "        df_select = df[['user_id', col,'day','context_timestamp']]\n",
    "        df_group =  df_select.groupby(['user_id', col,'day'])\n",
    "        group_max = df_group['context_timestamp'].transform('max')\n",
    "        group_min = df_group['context_timestamp'].transform('min')\n",
    "        final_feat['diff_maxtime_{}'.format(col)] = group_max - df['context_timestamp'].values\n",
    "        final_feat['diff_mintime_{}'.format(col)] = df['context_timestamp'].values -group_min\n",
    "    \n",
    "    train_feat = final_feat[(final_feat['day'] >= 18) & (final_feat['day'] <= 24)].drop('day', axis=1)       \n",
    "    test_feat = final_feat[final_feat['day']==25].drop('day', axis=1)   \n",
    "\n",
    "    dump_pickle(train_feat, path='../data/train_feature/103_diff_max_min.pkl')\n",
    "    dump_pickle(test_feat, path='../data/test_feature/103_diff_max_min.pkl')\n",
    "\n",
    "\n",
    "    # ================================= 当前日期前一天的cnt ===========================================\n",
    "    count_features = ['user_id', 'item_id', 'shop_id']\n",
    "    final_feat = df[count_features+['instance_id', 'day']]\n",
    "    for col in count_features:\n",
    "        count_name = '{}_lastday_count'.format(col)\n",
    "        count_all = None\n",
    "        for d in range(18, 24):\n",
    "            col_cnt = df[df['day'] == d - 1].groupby(by=col)['instance_id'].count().reset_index()\n",
    "            col_cnt.columns = [col, count_name]\n",
    "            col_cnt['day'] = d\n",
    "            count_all = pd.concat([count_all, col_cnt], axis=0)\n",
    "        final_feat = pd.merge(final_feat, count_all, on=[col, 'day'], how='left')\n",
    "#     final_feat = final_feat.drop(count_features+['day'], axis=1)\n",
    "    \n",
    "    train_feat = final_feat[(final_feat['day'] >= 18) & (final_feat['day'] <= 24)]  \n",
    "    test_feat = final_feat[final_feat['day']==25]\n",
    "    train_feat = train_feat.drop(count_features+['day'], axis=1)\n",
    "    test_feat = test_feat.drop(count_features+['day'], axis=1)\n",
    "    \n",
    "    dump_pickle(train_feat, path='../data/train_feature/103_last_day_count.pkl')\n",
    "    dump_pickle(test_feat, path='../data/test_feature/103_last_day_count.pkl')\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "user_time_count(df)\n",
    "end = time.time()\n",
    "print('time elapsed {}'.format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
