{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import BayesianSmoothing, load_pickle, dump_pickle, raw_data_path, valid_data_path\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "train = load_pickle('../data/train.pkl')\n",
    "test = load_pickle('../data/test.pkl')\n",
    "df = pd.concat([train, test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      " 17%|█▋        | 1/6 [00:01<00:06,  1.39s/it]\u001b[A\n",
      " 33%|███▎      | 2/6 [00:02<00:05,  1.49s/it]\u001b[A\n",
      " 50%|█████     | 3/6 [00:04<00:04,  1.60s/it]\u001b[A\n",
      " 67%|██████▋   | 4/6 [00:06<00:03,  1.73s/it]\u001b[A\n",
      " 83%|████████▎ | 5/6 [00:09<00:01,  1.82s/it]\u001b[A\n",
      "100%|██████████| 6/6 [00:11<00:00,  1.91s/it]\u001b[A\n",
      " 14%|█▍        | 1/7 [00:11<01:09, 11.60s/it]\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      " 17%|█▋        | 1/6 [00:00<00:02,  1.75it/s]\u001b[A\n",
      " 33%|███▎      | 2/6 [00:01<00:02,  1.94it/s]\u001b[A\n",
      " 50%|█████     | 3/6 [00:01<00:01,  1.91it/s]\u001b[A\n",
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.84it/s]\u001b[A\n",
      " 83%|████████▎ | 5/6 [00:02<00:00,  1.77it/s]\u001b[A\n",
      "100%|██████████| 6/6 [00:03<00:00,  1.70it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:15<00:38,  7.61s/it]\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      " 17%|█▋        | 1/6 [00:00<00:01,  4.45it/s]\u001b[A\n",
      " 33%|███▎      | 2/6 [00:00<00:00,  5.54it/s]\u001b[A\n",
      " 50%|█████     | 3/6 [00:00<00:00,  5.92it/s]\u001b[A\n",
      " 67%|██████▋   | 4/6 [00:00<00:00,  5.88it/s]\u001b[A\n",
      " 83%|████████▎ | 5/6 [00:00<00:00,  5.55it/s]\u001b[A\n",
      "100%|██████████| 6/6 [00:01<00:00,  5.36it/s]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:16<00:21,  5.49s/it]\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      " 17%|█▋        | 1/6 [00:00<00:01,  4.48it/s]\u001b[A\n",
      " 33%|███▎      | 2/6 [00:00<00:00,  6.10it/s]\u001b[A\n",
      " 50%|█████     | 3/6 [00:00<00:00,  6.65it/s]\u001b[A\n",
      " 67%|██████▋   | 4/6 [00:00<00:00,  6.49it/s]\u001b[A\n",
      " 83%|████████▎ | 5/6 [00:00<00:00,  6.08it/s]\u001b[A\n",
      "100%|██████████| 6/6 [00:01<00:00,  5.73it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:17<00:13,  4.41s/it]\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      " 17%|█▋        | 1/6 [00:00<00:01,  4.19it/s]\u001b[A\n",
      " 33%|███▎      | 2/6 [00:00<00:00,  5.75it/s]\u001b[A\n",
      " 50%|█████     | 3/6 [00:00<00:00,  6.24it/s]\u001b[A\n",
      " 67%|██████▋   | 4/6 [00:00<00:00,  6.24it/s]\u001b[A\n",
      " 83%|████████▎ | 5/6 [00:00<00:00,  5.95it/s]\u001b[A\n",
      "100%|██████████| 6/6 [00:01<00:00,  5.63it/s]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:18<00:07,  3.78s/it]\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      " 17%|█▋        | 1/6 [00:00<00:01,  4.38it/s]\u001b[A\n",
      " 33%|███▎      | 2/6 [00:00<00:00,  5.95it/s]\u001b[A\n",
      " 50%|█████     | 3/6 [00:00<00:00,  6.33it/s]\u001b[A\n",
      " 67%|██████▋   | 4/6 [00:00<00:00,  6.29it/s]\u001b[A\n",
      " 83%|████████▎ | 5/6 [00:00<00:00,  6.03it/s]\u001b[A\n",
      "100%|██████████| 6/6 [00:01<00:00,  5.70it/s]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:20<00:03,  3.35s/it]\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      " 17%|█▋        | 1/6 [00:00<00:01,  4.08it/s]\u001b[A\n",
      " 33%|███▎      | 2/6 [00:00<00:00,  5.67it/s]\u001b[A\n",
      " 50%|█████     | 3/6 [00:00<00:00,  6.22it/s]\u001b[A\n",
      " 67%|██████▋   | 4/6 [00:00<00:00,  6.09it/s]\u001b[A\n",
      " 83%|████████▎ | 5/6 [00:00<00:00,  5.81it/s]\u001b[A\n",
      "100%|██████████| 6/6 [00:01<00:00,  5.48it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:21<00:00,  3.05s/it]\n"
     ]
    }
   ],
   "source": [
    "iter_num = 200\n",
    "epsilon = 0.001\n",
    "'''\n",
    "1. 定义需要计算平滑点击率的变量\n",
    "2. 对于每一天，找出在这之前的所有点击行为\n",
    "3. 统计该变量的点击次数和购买次数\n",
    "'''\n",
    "smooth_cols = ['item_id', 'item_brand_id', 'item_city_id', 'item_price_level', 'item_sales_level','item_collected_level','item_pv_level']\n",
    "\n",
    "smooth_train = train[smooth_cols + ['instance_id', 'day']]\n",
    "smooth_test = test[smooth_cols + ['instance_id','day']]\n",
    "for col in tqdm(smooth_cols):\n",
    "    col_I = '{}_I'.format(col)\n",
    "    col_C = '{}_C'.format(col)\n",
    "    col_smooth_rate = '{}_smooth_rate'.format(col)\n",
    "    train[col_smooth_rate] = -1\n",
    "    smooth_all = pd.DataFrame({'day': train.day, '{}'.format(col): train[col]})\n",
    "    CVR_all = None\n",
    "    for day in tqdm(range(19, 25)):\n",
    "        I = train[train.day<day].groupby(col)['is_trade'].count().reset_index()\n",
    "        I.columns = [col, col_I]\n",
    "        C = train[train.day<day].groupby(col)['is_trade'].sum().reset_index()\n",
    "        C.columns = [col, col_C]\n",
    "        CVR = pd.concat([I, C[col_C]], axis=1)\n",
    "        CVR['day'] = day\n",
    "\n",
    "        smooth = BayesianSmoothing(1, 1)\n",
    "        smooth.update(CVR[col_I].values, CVR[col_C].values, iter_num, epsilon)\n",
    "        alpha = smooth.alpha\n",
    "        beta = smooth.beta\n",
    "        CVR[col_smooth_rate] = (CVR[col_C] + alpha) / (CVR[col_I] + alpha + beta)\n",
    "        CVR_all = pd.concat([CVR_all, CVR], axis=0)\n",
    "        \n",
    "    smooth_train = pd.merge(smooth_train, CVR_all[[col, 'day', col_smooth_rate]], on=[col, 'day'], how='left')\n",
    "    smooth_test = pd.merge(smooth_test, CVR_all[[col, 'day', col_smooth_rate]], on=[col, 'day'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['instance_id', 'item_id_smooth_rate', 'item_brand_id_smooth_rate',\n",
      "       'item_city_id_smooth_rate', 'item_price_level_smooth_rate',\n",
      "       'item_sales_level_smooth_rate', 'item_collected_level_smooth_rate',\n",
      "       'item_pv_level_smooth_rate'],\n",
      "      dtype='object')\n",
      "the shape of train (478087, 8)\n",
      "the shape of test (42888, 8)\n"
     ]
    }
   ],
   "source": [
    "smooth_train.drop(['day'], axis=1, inplace=True)\n",
    "smooth_test.drop(['day'], axis=1, inplace=True)\n",
    "smooth_train.drop(smooth_cols,axis=1,inplace=True)\n",
    "smooth_test.drop(smooth_cols,axis=1,inplace=True)\n",
    "print(smooth_train.columns)\n",
    "print('the shape of train {}'.format(smooth_train.shape))\n",
    "print('the shape of test {}'.format(smooth_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_pickle(smooth_train, path='../data/train_feature/301_smooth_item_features.pkl')\n",
    "dump_pickle(smooth_test, path='../data/test_feature/301_smooth_item_features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
